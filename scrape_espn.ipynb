{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a7fcc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f20a8fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put the webpage link for cricinfo website in webpage and use filename as the same as your match video's name\n",
    "\n",
    "webpage = 'https://www.espncricinfo.com/series/plunket-shield-2021-22-1279954/northern-districts-vs-wellington-12th-match-1280000/ball-by-ball-commentary'\n",
    "file_name = 'northern_v_wellington_plunket_new_day1'\n",
    "\n",
    "if not os.path.exists('./files/'):\n",
    "    os.mkdir('./files/')\n",
    "\n",
    "if not os.path.exists('./files/' + file_name):\n",
    "    os.mkdir('./files/' + file_name)\n",
    "\n",
    "loc = './files/' + file_name + '/scraped_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef3bf425",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('/usr/bin/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8eb3b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(webpage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8939a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(0.5)  # Allow 2 seconds for the web page to open\n",
    "scroll_pause_time = 1 # You can set your own pause time. My laptop is a bit slow so I use 1 sec\n",
    "screen_height = driver.execute_script(\"return window.screen.height;\")   # get the screen height of the web\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    # scroll one screen height each time\n",
    "    driver.execute_script(\"window.scrollTo(0, {screen_height}*{i});\".format(screen_height=screen_height, i=i))  \n",
    "    i += 1\n",
    "    time.sleep(scroll_pause_time)\n",
    "    # update scroll height each time after scrolled, as the scroll height can change after we scrolled the page\n",
    "    scroll_height = driver.execute_script(\"return document.body.scrollHeight;\")  \n",
    "    # Break the loop when the height we need to scroll to is larger than the total scroll height\n",
    "    if (screen_height) * i > scroll_height:\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b599e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['over', 'run', 'bowler', 'batter', 'long_commentary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41962612",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "commentary_1 = {}\n",
    "long_comm = []\n",
    "overs = []\n",
    "runs = []\n",
    "# short_comm = []\n",
    "bowler = []\n",
    "batter = []\n",
    "flag_i = 0\n",
    "\n",
    "divtag = soup.find_all('div', {'class': 'match-comment-padder'})\n",
    "\n",
    "for tag in divtag:\n",
    "    if ('Match State' in str(tag)):\n",
    "        flag_i += 1\n",
    "    if flag_i > 1:\n",
    "        continue\n",
    "    \n",
    "    tag_over = tag.find_all(\"span\", {\"class\": \"match-comment-over\"})\n",
    "    for t in tag_over:\n",
    "        over = round(float(t.text) - 0.1, 1)\n",
    "        print(over)\n",
    "        overs.append(over)\n",
    "#         overs.append(t.text)\n",
    "    \n",
    "    \n",
    "    long_comment = tag.find_all(\"div\", {\"class\": \"match-comment-long-text\"})\n",
    "    for t in long_comment:\n",
    "        long_comm.append(t.text)\n",
    "    \n",
    "    \n",
    "    tag_run = tag.find_all(\"div\", {\"class\": \"match-comment-run\"})\n",
    "    for t in tag_run:\n",
    "        runs.append(t.text)\n",
    "    \n",
    "    short_comment = tag.find_all(\"div\", {\"class\": \"match-comment-short-text\"})\n",
    "    for t in short_comment:\n",
    "        comm = t.text.split(',')\n",
    "        comm = comm[0].split(' to ')\n",
    "        bowler.append(comm[0])\n",
    "        batter.append(comm[1])\n",
    "        # short_comm.append(t.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f356f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(overs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cf6605b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f75526c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(long_comm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2b83bca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.over = overs\n",
    "# df.run = runs\n",
    "# # df.short_commentary = short_comm\n",
    "# df.bowler = bowler\n",
    "# df.batter = batter\n",
    "# df.long_commentary = long_comm\n",
    "\n",
    "j = 0\n",
    "for i in overs:\n",
    "    if i not in commentary_1.keys():\n",
    "        commentary_1[i] = {'run': runs[j], 'bowler': bowler[j], 'batter': batter[j]}  # ,'comm':long_comm[j]\n",
    "    else:\n",
    "        commentary_1[i]['run'] = commentary_1[i]['run'] + ' ' + runs[j]\n",
    "#         commentary_1[i]['comm'] = commentary_1[i]['comm'] + ' ' + long_comm[j]\n",
    "    j+=1\n",
    "    \n",
    "    \n",
    "with open(loc + '_1.json', 'w') as f:\n",
    "    json.dump(commentary_1 ,f)\n",
    "\n",
    "\n",
    "# df.to_csv(loc + '_1' + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cb181f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([22.3, 22.2, 22.1, 22.0, 21.5, 21.4, 21.3, 21.2, 21.1, 21.0, 20.5, 20.4, 20.3, 20.2, 20.1, 20.0, 19.5, 19.4, 19.3, 19.2, 19.1, 19.0, 18.5, 18.4, 18.3, 18.2, 18.1, 18.0, 17.5, 17.4, 17.3, 17.2, 17.1, 17.0, 16.5, 16.4, 16.3, 16.2, 16.1, 16.0, 15.5, 15.4, 15.3, 15.2, 15.1, 15.0, 14.5, 14.4, 14.3, 14.2, 14.1, 14.0, 13.5, 13.4, 13.3, 13.2, 13.1, 13.0, 12.5, 12.4, 12.3, 12.2, 12.1, 12.0, 11.5, 11.4, 11.3, 11.2, 11.1, 11.0, 10.5, 10.4, 10.3, 10.2, 10.1, 10.0, 9.5, 9.4, 9.3, 9.2, 9.1, 9.0, 8.5, 8.4, 8.3, 8.2, 8.1, 8.0, 7.5, 7.4, 7.3, 7.2, 7.1, 7.0, 6.5, 6.4, 6.3, 6.2, 6.1, 6.0, 5.5, 5.4, 5.3, 5.2, 5.1, 5.0, 4.5, 4.4, 4.3, 4.2, 4.1, 4.0, 3.5, 3.4, 3.3, 3.2, 3.1, 3.0, 2.5, 2.4, 2.3, 2.2, 2.1, 2.0, 1.5, 1.4, 1.3, 1.2, 1.1, 1.0, 0.5, 0.4, 0.3, 0.2, 0.1, 0.0])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commentary_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fb78c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Getting the first match"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a4b4215",
   "metadata": {},
   "source": [
    "## Second innings scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b6a720b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(0.5)  # Allow 2 seconds for the web page to open\n",
    "scroll_pause_time = 1 # You can set your own pause time. My laptop is a bit slow so I use 1 sec\n",
    "screen_height = driver.execute_script(\"return window.screen.height;\")   # get the screen height of the web\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    # scroll one screen height each time\n",
    "    driver.execute_script(\"window.scrollTo(0, {screen_height}*{i});\".format(screen_height=screen_height, i=i))  \n",
    "    i += 1\n",
    "    time.sleep(scroll_pause_time)\n",
    "    # update scroll height each time after scrolled, as the scroll height can change after we scrolled the page\n",
    "    scroll_height = driver.execute_script(\"return document.body.scrollHeight;\")  \n",
    "    # Break the loop when the height we need to scroll to is larger than the total scroll height\n",
    "    if (screen_height) * i > scroll_height:\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "95926970",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame(columns=['over', 'run', 'bowler', 'batter', 'long_commentary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b8de2ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "commentary_0 = {}\n",
    "long_comm = []\n",
    "overs = []\n",
    "runs = []\n",
    "# short_comm = []\n",
    "bowler = []\n",
    "batter = []\n",
    "\n",
    "divtag = soup.find_all('div', {'class': 'match-comment-padder'})\n",
    "\n",
    "for tag in divtag:\n",
    "    long_comment = tag.find_all(\"div\", {\"class\": \"match-comment-long-text\"})\n",
    "    for t in long_comment:\n",
    "        long_comm.append(t.text)\n",
    "        \n",
    "    tag_over = tag.find_all(\"span\", {\"class\": \"match-comment-over\"})\n",
    "    for t in tag_over:\n",
    "        over = round(float(t.text) - 0.1, 1)\n",
    "        overs.append(over)\n",
    "        #overs.append(t.text)\n",
    "    \n",
    "    tag_run = tag.find_all(\"div\", {\"class\": \"match-comment-run\"})\n",
    "    for t in tag_run:\n",
    "        runs.append(t.text)\n",
    "    \n",
    "    short_comment = tag.find_all(\"div\", {\"class\": \"match-comment-short-text\"})\n",
    "    for t in short_comment:\n",
    "        comm = t.text.split(',')\n",
    "        comm = comm[0].split(' to ')\n",
    "        bowler.append(comm[0])\n",
    "        batter.append(comm[1])\n",
    "        # short_comm.append(t.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3f1cc1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(overs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "494727cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(long_comm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8a17e6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new.over = overs\n",
    "# df_new.run = runs\n",
    "# # df_new.short_commentary = short_comm\n",
    "# df_new.long_commentary = long_comm\n",
    "# df_new.bowler = bowler\n",
    "# df_new.batter = batter\n",
    "\n",
    "\n",
    "j = 0\n",
    "for i in overs:\n",
    "    if i not in commentary_0.keys():\n",
    "        commentary_0[i] = {'run': runs[j], 'bowler': bowler[j], 'batter': batter[j]} # ,'comm':long_comm[j]\n",
    "    else:\n",
    "        commentary_0[i]['run'] = commentary_0[i]['run'] + ' ' + runs[j]\n",
    "#         commentary_0[i]['comm'] = commentary_0[i]['comm'] + ' ' + long_comm[j]\n",
    "    j+=1\n",
    "    \n",
    "    \n",
    "with open(loc + '_0.json', 'w') as f:\n",
    "    json.dump(commentary_0 ,f)\n",
    "\n",
    "# df_new.to_csv(loc + '_0' + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d992a3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([33.5, 33.4, 33.3, 33.2, 33.1, 33.0, 32.5, 32.4, 32.3, 32.2, 32.1, 32.0, 31.5, 31.4, 31.3, 31.2, 31.1, 31.0, 30.5, 30.4, 30.3, 30.2, 30.1, 30.0, 29.5, 29.4, 29.3, 29.2, 29.1, 29.0, 28.5, 28.4, 28.3, 28.2, 28.1, 28.0, 27.5, 27.4, 27.3, 27.2, 27.1, 27.0, 26.5, 26.4, 26.3, 26.2, 26.1, 26.0, 25.5, 25.4, 25.3, 25.2, 25.1, 25.0, 24.5, 24.4, 24.3, 24.2, 24.1, 24.0, 23.5, 23.4, 23.3, 23.2, 23.1, 23.0, 22.5, 22.4, 22.3, 22.2, 22.1, 22.0, 21.5, 21.4, 21.3, 21.2, 21.1, 21.0, 20.5, 20.4, 20.3, 20.2, 20.1, 20.0, 19.5, 19.4, 19.3, 19.2, 19.1, 19.0, 18.5, 18.4, 18.3, 18.2, 18.1, 18.0, 17.5, 17.4, 17.3, 17.2, 17.1, 17.0, 16.5, 16.4, 16.3, 16.2, 16.1, 16.0, 15.5, 15.4, 15.3, 15.2, 15.1, 15.0, 14.5, 14.4, 14.3, 14.2, 14.1, 14.0, 13.5, 13.4, 13.3, 13.2, 13.1, 13.0, 12.5, 12.4, 12.3, 12.2, 12.1, 12.0, 11.5, 11.4, 11.3, 11.2, 11.1, 11.0, 10.5, 10.4, 10.3, 10.2, 10.1, 10.0, 9.5, 9.4, 9.3, 9.2, 9.1, 9.0, 8.5, 8.4, 8.3, 8.2, 8.1, 8.0, 7.5, 7.4, 7.3, 7.2, 7.1, 7.0, 6.5, 6.4, 6.3, 6.2, 6.1, 6.0, 5.5, 5.4, 5.3, 5.2, 5.1, 5.0, 4.5, 4.4, 4.3, 4.2, 4.1, 4.0, 3.5, 3.4, 3.3, 3.2, 3.1, 3.0, 2.5, 2.4, 2.3, 2.2, 2.1, 2.0, 1.5, 1.4, 1.3, 1.2, 1.1, 1.0, 0.5, 0.4, 0.3, 0.2, 0.1, 0.0])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commentary_0.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7781de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
